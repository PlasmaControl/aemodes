{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6394f37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafa1ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from aemodes.models.detection.seldnet import SELDNetModel\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d74e0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATA_PATH = Path('/scratch/gpfs/nc1514/aemodes/data/co2_250_detector.pkl')\n",
    "OUTPUT_PATH = Path('/scratch/gpfs/nc1514/aemodes/data/co2_250_detector_2.pkl')\n",
    "MODEL_DIR = Path('/scratch/gpfs/nc1514/aemodes/model/seldnet_labels')\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Training settings\n",
    "NUM_LABELS = 5\n",
    "NUM_EPOCHS = 30\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-3\n",
    "THRESHOLD = 0.5  # For inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93172847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "with open(DATA_PATH, 'rb') as f:\n",
    "    train_shots, X_train, y_train, valid_shots, X_valid, y_valid = pickle.load(f)\n",
    "\n",
    "print(f\"Train shots: {len(train_shots)}\")\n",
    "print(f\"Valid shots: {len(valid_shots)}\")\n",
    "print(f\"X_train[0] keys: {X_train[0].keys()}\")\n",
    "print(f\"X_train[0]['r0'] shape: {X_train[0]['r0'].shape}\")\n",
    "print(f\"y_train[0] shape: {y_train[0].shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2753d329",
   "metadata": {},
   "source": [
    "## Binary Symmetric Cross Entropy Loss\n",
    "\n",
    "Adapted from [HanxunH/SCELoss-Reproduce](https://github.com/HanxunH/SCELoss-Reproduce/blob/master/loss.py) for binary classification with sigmoid outputs.\n",
    "\n",
    "SCE = α * BCE + β * RCE (Reverse Cross Entropy)\n",
    "\n",
    "This loss is robust to noisy labels because RCE penalizes confident predictions less harshly when labels might be incorrect.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e3daba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinarySCELoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Binary Symmetric Cross Entropy Loss for noisy label training.\n",
    "    \n",
    "    Adapted from https://github.com/HanxunH/SCELoss-Reproduce/blob/master/loss.py\n",
    "    for binary classification with sigmoid outputs.\n",
    "    \n",
    "    SCE = alpha * BCE + beta * RCE\n",
    "    - BCE: standard binary cross entropy\n",
    "    - RCE: reverse cross entropy (labels predicting model outputs)\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha=1.0, beta=0.5):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "    \n",
    "    def forward(self, pred_logits, targets):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            pred_logits: Raw logits from model (B, T) or (B, T, 1)\n",
    "            targets: Binary labels (B, T) with values in {0, 1}\n",
    "        \"\"\"\n",
    "        # Flatten if needed\n",
    "        pred_logits = pred_logits.view(-1)\n",
    "        targets = targets.view(-1).float()\n",
    "        \n",
    "        # Get probabilities\n",
    "        pred_prob = torch.sigmoid(pred_logits)\n",
    "        \n",
    "        # Clamp for numerical stability\n",
    "        pred_prob = torch.clamp(pred_prob, min=1e-7, max=1.0 - 1e-7)\n",
    "        targets_clamped = torch.clamp(targets, min=1e-4, max=1.0 - 1e-4)\n",
    "        \n",
    "        # BCE: -[y*log(p) + (1-y)*log(1-p)]\n",
    "        bce = F.binary_cross_entropy_with_logits(pred_logits, targets, reduction='mean')\n",
    "        \n",
    "        # RCE: -[p*log(y) + (1-p)*log(1-y)]\n",
    "        rce = -(pred_prob * torch.log(targets_clamped) + \n",
    "                (1 - pred_prob) * torch.log(1 - targets_clamped))\n",
    "        rce = rce.mean()\n",
    "        \n",
    "        # Combined loss\n",
    "        loss = self.alpha * bce + self.beta * rce\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d6fd79",
   "metadata": {},
   "source": [
    "## Dataset and DataModule\n",
    "\n",
    "Single-label dataset that returns data for training one specific label class at a time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f893fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleLabelShotDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset that extracts a single label class for per-class training.\n",
    "    Based on ShotDataset from aemodes.utils.dataset but for single-label binary classification.\n",
    "    \"\"\"\n",
    "    def __init__(self, shots, X, y, label_idx):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            shots: List of shot identifiers\n",
    "            X: List of dicts with keys 'r0', 'v1', 'v2', 'v3'\n",
    "            y: List of arrays with shape (T, num_labels)\n",
    "            label_idx: Which label index to extract (0-4)\n",
    "        \"\"\"\n",
    "        self.shots = shots\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.label_idx = label_idx\n",
    "        \n",
    "        # Window parameters (matching original ShotDataset)\n",
    "        lenshot = 3905\n",
    "        self.nwin = 11\n",
    "        self.lenwin = lenshot // self.nwin\n",
    "        self.hoplen = lenshot // self.nwin\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.shots) * self.nwin\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        shot_idx, win_idx = idx // self.nwin, idx % self.nwin\n",
    "        start_idx = win_idx * self.hoplen\n",
    "        end_idx = start_idx + self.lenwin\n",
    "        \n",
    "        # Stack 4 channels: (4, T, F)\n",
    "        # Each X_dict channel has shape (T_full, F), slicing gives (T, F)\n",
    "        X_dict = self.X[shot_idx]\n",
    "        X = np.stack([\n",
    "            X_dict['r0'][start_idx:end_idx],\n",
    "            X_dict['v1'][start_idx:end_idx],\n",
    "            X_dict['v2'][start_idx:end_idx],\n",
    "            X_dict['v3'][start_idx:end_idx]\n",
    "        ])\n",
    "        # Shape after stack: (4, T, F) - keep as is, model expects (B, C, T, F)\n",
    "        X = torch.tensor(X, dtype=torch.float32)\n",
    "        \n",
    "        # Get single label: (T,)\n",
    "        y_full = self.y[shot_idx][start_idx:end_idx]  # (T, num_labels)\n",
    "        y = torch.tensor(y_full[:, self.label_idx], dtype=torch.float32)\n",
    "        \n",
    "        return {\n",
    "            'shot': self.shots[shot_idx],\n",
    "            'X': X,\n",
    "            'y': y,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a160da3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleLabelDataModule(L.LightningDataModule):\n",
    "    \"\"\"Lightning DataModule for single-label training.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        train_shots, X_train, y_train,\n",
    "        valid_shots, X_valid, y_valid,\n",
    "        label_idx,\n",
    "        batch_size=32,\n",
    "        num_workers=4,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.train_shots = train_shots\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.valid_shots = valid_shots\n",
    "        self.X_valid = X_valid\n",
    "        self.y_valid = y_valid\n",
    "        self.label_idx = label_idx\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = SingleLabelShotDataset(\n",
    "            self.train_shots, self.X_train, self.y_train, self.label_idx\n",
    "        )\n",
    "        self.valid_dataset = SingleLabelShotDataset(\n",
    "            self.valid_shots, self.X_valid, self.y_valid, self.label_idx\n",
    "        )\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=True,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.valid_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=False,\n",
    "            pin_memory=True,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3aa3c6",
   "metadata": {},
   "source": [
    "## SELDNet Lightning Module\n",
    "\n",
    "Wraps SELDNetModel for Lightning training with Binary SCE Loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dabf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lightweight_params():\n",
    "    \"\"\"Lightweight SELDNet parameters (~500K params instead of ~5M).\"\"\"\n",
    "    return {\n",
    "        'pool_sizes': [9, 8, 2],\n",
    "        'conv_channels': 24,      # Reduced from 64\n",
    "        'dropout_rate': 0.1,      # Add some regularization\n",
    "        'nb_cnn2d_filt': 24,      # Reduced from 64\n",
    "        'rnn_sizes': [64, 64],    # Reduced from [128, 128]\n",
    "        'fnn_sizes': [64],        # Reduced from [128]\n",
    "    }\n",
    "\n",
    "\n",
    "class SELDNetLightningModule(L.LightningModule):\n",
    "    \"\"\"Lightning module for SELDNet with Binary SCE Loss.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size=(4, 355, 128),\n",
    "        learning_rate=1e-3,\n",
    "        sce_alpha=1.0,\n",
    "        sce_beta=0.5,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # Use lightweight parameters (~500K params)\n",
    "        params = lightweight_params()\n",
    "        \n",
    "        # Build model for single-label output\n",
    "        self.model = SELDNetModel(\n",
    "            input_size=input_size,\n",
    "            output_size=(input_size[1], 1),  # (T, 1) - single label\n",
    "            params=params,\n",
    "        )\n",
    "        \n",
    "        # Binary SCE Loss\n",
    "        self.criterion = BinarySCELoss(alpha=sce_alpha, beta=sce_beta)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X = batch['X']  # (B, 4, T, F)\n",
    "        y = batch['y']  # (B, T)\n",
    "        \n",
    "        logits = self.model(X)  # (B, T, 1)\n",
    "        logits = logits.squeeze(-1)  # (B, T)\n",
    "        \n",
    "        loss = self.criterion(logits, y)\n",
    "        \n",
    "        # Compute accuracy\n",
    "        with torch.no_grad():\n",
    "            preds = (torch.sigmoid(logits) > 0.5).float()\n",
    "            acc = (preds == y).float().mean()\n",
    "        \n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log('train_acc', acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X = batch['X']\n",
    "        y = batch['y']\n",
    "        \n",
    "        logits = self.model(X).squeeze(-1)\n",
    "        loss = self.criterion(logits, y)\n",
    "        \n",
    "        # Compute accuracy\n",
    "        preds = (torch.sigmoid(logits) > 0.5).float()\n",
    "        acc = (preds == y).float().mean()\n",
    "        \n",
    "        self.log('val_loss', loss, on_epoch=True, prog_bar=True)\n",
    "        self.log('val_acc', acc, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):  # type: ignore[override]\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            self.parameters(),\n",
    "            lr=self.learning_rate,\n",
    "            weight_decay=1e-4,\n",
    "        )\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer,\n",
    "            T_max=NUM_EPOCHS,\n",
    "            eta_min=1e-6,\n",
    "        )\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': scheduler,\n",
    "                'interval': 'epoch',\n",
    "            }\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82d81ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify model parameter count\n",
    "test_model = SELDNetLightningModule(input_size=(4, 355, 128))\n",
    "num_params = sum(p.numel() for p in test_model.parameters())\n",
    "print(f\"Model parameters: {num_params:,} (~{num_params/1e6:.2f}M)\")\n",
    "del test_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc7964f",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "Train 5 separate SELDNet models, one for each label class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda5faaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_label_model(label_idx, train_shots, X_train, y_train, valid_shots, X_valid, y_valid):\n",
    "    \"\"\"Train a SELDNet model for a single label class.\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training model for Label {label_idx}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Create data module\n",
    "    data_module = SingleLabelDataModule(\n",
    "        train_shots, X_train, y_train,\n",
    "        valid_shots, X_valid, y_valid,\n",
    "        label_idx=label_idx,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_workers=4,\n",
    "    )\n",
    "    \n",
    "    # Determine input size from data\n",
    "    data_module.setup()\n",
    "    sample = data_module.train_dataset[0]\n",
    "    input_size = tuple(sample['X'].shape)  # (4, T, F)\n",
    "    print(f\"Input size: {input_size}\")\n",
    "    \n",
    "    # Create model\n",
    "    model = SELDNetLightningModule(\n",
    "        input_size=input_size,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        sce_alpha=1.0,\n",
    "        sce_beta=0.5,\n",
    "    )\n",
    "    \n",
    "    # Setup callbacks\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=MODEL_DIR,\n",
    "        filename=f'seldnet_label{label_idx}-{{epoch:02d}}-{{val_loss:.4f}}',\n",
    "        save_top_k=1,\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "    )\n",
    "    \n",
    "    early_stop_callback = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        mode='min',\n",
    "    )\n",
    "    \n",
    "    # Create trainer\n",
    "    trainer = L.Trainer(\n",
    "        max_epochs=NUM_EPOCHS,\n",
    "        accelerator='auto',\n",
    "        devices='auto',\n",
    "        callbacks=[checkpoint_callback, early_stop_callback],\n",
    "        enable_progress_bar=True,\n",
    "        log_every_n_steps=10,\n",
    "        precision='bf16-mixed',\n",
    "        logger=False,\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    trainer.fit(model, data_module)\n",
    "    \n",
    "    # Load best checkpoint\n",
    "    best_model_path = checkpoint_callback.best_model_path\n",
    "    print(f\"Best model saved to: {best_model_path}\")\n",
    "    \n",
    "    # Load and return the best model\n",
    "    best_model = SELDNetLightningModule.load_from_checkpoint(best_model_path)\n",
    "    best_model.eval()\n",
    "    \n",
    "    return best_model, best_model_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da81440e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models for all labels\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "trained_models = {}\n",
    "model_paths = {}\n",
    "\n",
    "for label_idx in range(NUM_LABELS):\n",
    "    model, path = train_label_model(\n",
    "        label_idx,\n",
    "        train_shots, X_train, y_train,\n",
    "        valid_shots, X_valid, y_valid,\n",
    "    )\n",
    "    trained_models[label_idx] = model\n",
    "    model_paths[label_idx] = path\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"All models trained!\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcad5905",
   "metadata": {},
   "source": [
    "## Inference and Label Refinement\n",
    "\n",
    "Run inference on all data (train + valid) and apply temporal smoothing to generate improved labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba2b1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_smooth(predictions, kernel_size=5):\n",
    "    \"\"\"\n",
    "    Apply temporal smoothing using a moving average filter.\n",
    "    Helps clean up noisy per-frame predictions.\n",
    "    \"\"\"\n",
    "    if kernel_size <= 1:\n",
    "        return predictions\n",
    "    \n",
    "    # Pad and convolve\n",
    "    pad = kernel_size // 2\n",
    "    kernel = np.ones(kernel_size) / kernel_size\n",
    "    \n",
    "    smoothed = np.convolve(predictions, kernel, mode='same')\n",
    "    return smoothed\n",
    "\n",
    "\n",
    "def run_inference_on_shot(models, X_dict, lenshot=3905, nwin=11, threshold=0.5, smooth_kernel=5):\n",
    "    \"\"\"\n",
    "    Run inference on a single shot using all trained models.\n",
    "    \n",
    "    Returns:\n",
    "        predictions: Array of shape (T, num_labels) with binary predictions\n",
    "    \"\"\"\n",
    "    lenwin = lenshot // nwin\n",
    "    hoplen = lenshot // nwin\n",
    "    num_labels = len(models)\n",
    "    \n",
    "    # Accumulate predictions across windows\n",
    "    all_predictions = np.zeros((lenshot, num_labels))\n",
    "    counts = np.zeros(lenshot)\n",
    "    \n",
    "    for win_idx in range(nwin):\n",
    "        start_idx = win_idx * hoplen\n",
    "        end_idx = start_idx + lenwin\n",
    "        \n",
    "        # Prepare input: (1, 4, T, F)\n",
    "        # Each channel has shape (T_full, F), slicing gives (T, F)\n",
    "        X = np.stack([\n",
    "            X_dict['r0'][start_idx:end_idx],\n",
    "            X_dict['v1'][start_idx:end_idx],\n",
    "            X_dict['v2'][start_idx:end_idx],\n",
    "            X_dict['v3'][start_idx:end_idx]\n",
    "        ])\n",
    "        # Shape: (4, T, F) -> add batch dim -> (1, 4, T, F)\n",
    "        X = torch.tensor(X, dtype=torch.float32).unsqueeze(0)\n",
    "        X = X.to(device)\n",
    "        \n",
    "        # Run each model\n",
    "        for label_idx, model in models.items():\n",
    "            model = model.to(device)\n",
    "            with torch.no_grad():\n",
    "                logits = model(X).squeeze()  # (T,)\n",
    "                probs = torch.sigmoid(logits).cpu().numpy()\n",
    "            \n",
    "            all_predictions[start_idx:end_idx, label_idx] += probs\n",
    "        \n",
    "        counts[start_idx:end_idx] += 1\n",
    "    \n",
    "    # Average overlapping predictions\n",
    "    counts = np.maximum(counts, 1)[:, None]\n",
    "    all_predictions = all_predictions / counts\n",
    "    \n",
    "    # Apply temporal smoothing and threshold\n",
    "    for label_idx in range(num_labels):\n",
    "        all_predictions[:, label_idx] = temporal_smooth(\n",
    "            all_predictions[:, label_idx], \n",
    "            kernel_size=smooth_kernel\n",
    "        )\n",
    "    \n",
    "    # Threshold to binary\n",
    "    binary_predictions = (all_predictions > threshold).astype(np.float32)\n",
    "    \n",
    "    return binary_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624de1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference on all training data\n",
    "print(\"Running inference on training data...\")\n",
    "y_train_improved = []\n",
    "\n",
    "for idx in tqdm(range(len(train_shots))):\n",
    "    X_dict = X_train[idx]\n",
    "    lenshot = X_dict['r0'].shape[0]\n",
    "    \n",
    "    improved_labels = run_inference_on_shot(\n",
    "        trained_models, \n",
    "        X_dict, \n",
    "        lenshot=lenshot,\n",
    "        threshold=THRESHOLD,\n",
    "        smooth_kernel=5,\n",
    "    )\n",
    "    y_train_improved.append(improved_labels)\n",
    "\n",
    "print(f\"Improved labels for {len(y_train_improved)} training shots\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081a49f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference on all validation data\n",
    "print(\"Running inference on validation data...\")\n",
    "y_valid_improved = []\n",
    "\n",
    "for idx in tqdm(range(len(valid_shots))):\n",
    "    X_dict = X_valid[idx]\n",
    "    lenshot = X_dict['r0'].shape[0]\n",
    "    \n",
    "    improved_labels = run_inference_on_shot(\n",
    "        trained_models, \n",
    "        X_dict, \n",
    "        lenshot=lenshot,\n",
    "        threshold=THRESHOLD,\n",
    "        smooth_kernel=5,\n",
    "    )\n",
    "    y_valid_improved.append(improved_labels)\n",
    "\n",
    "print(f\"Improved labels for {len(y_valid_improved)} validation shots\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83946202",
   "metadata": {},
   "source": [
    "## Save Improved Labels\n",
    "\n",
    "Save the improved labels in the same format as the original pickle file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4f6f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify shapes match original data\n",
    "print(\"Verifying data shapes...\")\n",
    "print(f\"Original y_train[0] shape: {y_train[0].shape}\")\n",
    "print(f\"Improved y_train[0] shape: {y_train_improved[0].shape}\")\n",
    "print(f\"Original y_valid[0] shape: {y_valid[0].shape}\")\n",
    "print(f\"Improved y_valid[0] shape: {y_valid_improved[0].shape}\")\n",
    "\n",
    "# Compare statistics between original and improved labels\n",
    "print(\"\\nLabel statistics comparison:\")\n",
    "for label_idx in range(NUM_LABELS):\n",
    "    orig_train_mean = np.mean([y[:, label_idx].mean() for y in y_train])\n",
    "    impr_train_mean = np.mean([y[:, label_idx].mean() for y in y_train_improved])\n",
    "    orig_valid_mean = np.mean([y[:, label_idx].mean() for y in y_valid])\n",
    "    impr_valid_mean = np.mean([y[:, label_idx].mean() for y in y_valid_improved])\n",
    "    \n",
    "    print(f\"  Label {label_idx}:\")\n",
    "    print(f\"    Train - Original: {orig_train_mean:.4f}, Improved: {impr_train_mean:.4f}\")\n",
    "    print(f\"    Valid - Original: {orig_valid_mean:.4f}, Improved: {impr_valid_mean:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a8524b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save improved dataset in the same format as original\n",
    "# Format: [train_shots, X_train, y_train, valid_shots, X_valid, y_valid]\n",
    "improved_data = [\n",
    "    train_shots,\n",
    "    X_train,\n",
    "    y_train_improved,\n",
    "    valid_shots,\n",
    "    X_valid,\n",
    "    y_valid_improved,\n",
    "]\n",
    "\n",
    "with open(OUTPUT_PATH, 'wb') as f:\n",
    "    pickle.dump(improved_data, f)\n",
    "\n",
    "print(f\"\\nSaved improved dataset to: {OUTPUT_PATH}\")\n",
    "print(f\"File size: {OUTPUT_PATH.stat().st_size / 1e6:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f862e8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the saved file can be loaded correctly\n",
    "print(\"Verifying saved file...\")\n",
    "with open(OUTPUT_PATH, 'rb') as f:\n",
    "    loaded_data = pickle.load(f)\n",
    "\n",
    "loaded_train_shots, loaded_X_train, loaded_y_train, \\\n",
    "loaded_valid_shots, loaded_X_valid, loaded_y_valid = loaded_data\n",
    "\n",
    "print(f\"Loaded train shots: {len(loaded_train_shots)}\")\n",
    "print(f\"Loaded valid shots: {len(loaded_valid_shots)}\")\n",
    "print(f\"Loaded y_train[0] shape: {loaded_y_train[0].shape}\")\n",
    "print(f\"Loaded y_valid[0] shape: {loaded_y_valid[0].shape}\")\n",
    "print(\"\\nDataset improvement complete!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
